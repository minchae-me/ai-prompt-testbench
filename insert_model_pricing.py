#!/usr/bin/env python3
"""
ëª¨ë¸ ê°€ê²© ì •ë³´ë¥¼ BigQueryì— ì‚½ì…í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
OpenAI APIì—ì„œ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì™€ì„œ ìµœì‹  ê°€ê²© ì •ë³´ë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
"""

import os
import re
from datetime import datetime
from pathlib import Path
from google.cloud import bigquery
from openai import OpenAI

# .env íŒŒì¼ ë¡œë“œ
try:
    from dotenv import load_dotenv

    env_path = Path(__file__).parent / ".env"
    if env_path.exists():
        load_dotenv(env_path)
        print(f"âœ… .env íŒŒì¼ ë¡œë“œë¨: {env_path}")
    else:
        print(f"âš ï¸ .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {env_path}")
except ImportError:
    print("âš ï¸ python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ ì§ì ‘ ì„¤ì •í•´ì£¼ì„¸ìš”.")

PROJECT_ID = os.environ.get("GCP_PROJECT") or os.environ.get("GOOGLE_CLOUD_PROJECT")
DATASET_ID = "ai_sandbox"
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

if not PROJECT_ID:
    print("âŒ í™˜ê²½ ë³€ìˆ˜ GCP_PROJECT ë˜ëŠ” GOOGLE_CLOUD_PROJECTë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    print("ğŸ’¡ .env íŒŒì¼ì— ë‹¤ìŒê³¼ ê°™ì´ ì¶”ê°€í•˜ì„¸ìš”:")
    print("   GCP_PROJECT=your_project_id")
    exit(1)

if not OPENAI_API_KEY:
    print("âŒ í™˜ê²½ ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    print("ğŸ’¡ .env íŒŒì¼ì— ë‹¤ìŒê³¼ ê°™ì´ ì¶”ê°€í•˜ì„¸ìš”:")
    print("   OPENAI_API_KEY=sk-your_api_key_here")
    exit(1)

print(f"í”„ë¡œì íŠ¸: {PROJECT_ID}")
print(f"ë°ì´í„°ì…‹: {DATASET_ID}")

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
bq_client = bigquery.Client(project=PROJECT_ID)
openai_client = OpenAI(api_key=OPENAI_API_KEY)


def get_openai_chat_models():
    """OpenAI APIì—ì„œ ì±„íŒ… ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        print("ğŸ“¡ OpenAI APIì—ì„œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì¤‘...")
        models = openai_client.models.list()

        # ì±„íŒ…ìš©ì´ ì•„ë‹Œ ëª¨ë¸ë“¤ í•„í„°ë§
        blocked_pattern = re.compile(
            r"(whisper|tts|embedding|dall-e|image|moderation|audio)", re.I
        )

        chat_models = []
        for model in models:
            if not blocked_pattern.search(model.id):
                chat_models.append(model.id)

        chat_models.sort()
        print(f"âœ… ì±„íŒ… ëª¨ë¸ {len(chat_models)}ê°œ ë°œê²¬")

        return chat_models
    except Exception as e:
        print(f"âŒ OpenAI ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []


def get_model_pricing_data(model_name: str):
    """ëª¨ë¸ëª…ì— ë”°ë¥¸ ì¶”ì • ê°€ê²© ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""

    # OpenAI ê³µì‹ ê°€ê²© ì •ë³´ (2024ë…„ 12ì›” ê¸°ì¤€ - platform.openai.com/docs/pricing)
    known_prices = {
        # ===========================================
        # GPT-4o ê³„ì—´ (Latest Generation) - 2024ë…„ 12ì›” ê¸°ì¤€
        # ===========================================
        "gpt-4o": {"input": 0.005, "output": 0.015},  # $5.00/$15.00 per 1M tokens
        "gpt-4o-2024-11-20": {"input": 0.005, "output": 0.015},
        "gpt-4o-2024-08-06": {"input": 0.005, "output": 0.015},
        "gpt-4o-2024-05-13": {"input": 0.005, "output": 0.015},
        "gpt-4o-mini": {
            "input": 0.00015,
            "output": 0.0006,
        },  # $0.15/$0.60 per 1M tokens
        "gpt-4o-mini-2024-07-18": {"input": 0.00015, "output": 0.0006},
        "gpt-4o-audio-preview": {"input": 0.005, "output": 0.015},  # Audio-enabled
        "gpt-4o-realtime-preview": {"input": 0.005, "output": 0.015},  # Real-time API
        "gpt-4o-vision": {"input": 0.005, "output": 0.015},  # Vision-enabled
        # ===========================================
        # O1 ê³„ì—´ (Reasoning Models)
        # ===========================================
        "o1-preview": {"input": 0.015, "output": 0.06},
        "o1-preview-2024-09-12": {"input": 0.015, "output": 0.06},
        "o1-mini": {"input": 0.003, "output": 0.012},
        "o1-mini-2024-09-12": {"input": 0.003, "output": 0.012},
        # ===========================================
        # O3 ê³„ì—´ (Next Generation Reasoning - December 2024)
        # ===========================================
        "o3-mini": {"input": 0.004, "output": 0.016},  # Estimated pricing
        "o3": {"input": 0.02, "output": 0.08},  # Estimated pricing
        "o3-preview": {"input": 0.02, "output": 0.08},  # Preview version
        # ===========================================
        # GPT-5 ê³„ì—´ (Latest Models)
        # ===========================================
        "gpt-5": {"input": 0.00125, "output": 0.01},  # $1.25/$10.00 per 1M tokens
        "gpt-5-mini": {"input": 0.00025, "output": 0.002},  # $0.25/$2.00 per 1M tokens
        "gpt-5-nano": {"input": 0.0005, "output": 0.004},  # $0.50/$4.00 per 1M tokens
        "gpt-5-chat-latest": {
            "input": 0.00125,
            "output": 0.01,
        },  # $1.25/$10.00 per 1M tokens
        # ===========================================
        # GPT-4 Turbo ê³„ì—´
        # ===========================================
        "gpt-4-turbo": {"input": 0.01, "output": 0.03},
        "gpt-4-turbo-2024-04-09": {"input": 0.01, "output": 0.03},
        "gpt-4-turbo-preview": {"input": 0.01, "output": 0.03},
        "gpt-4-0125-preview": {"input": 0.01, "output": 0.03},
        "gpt-4-1106-preview": {"input": 0.01, "output": 0.03},
        "gpt-4-1106-vision-preview": {"input": 0.01, "output": 0.03},
        # ===========================================
        # GPT-4 Standard ê³„ì—´
        # ===========================================
        "gpt-4": {"input": 0.03, "output": 0.06},
        "gpt-4-0613": {"input": 0.03, "output": 0.06},
        "gpt-4-0314": {"input": 0.03, "output": 0.06},
        "gpt-4-32k": {"input": 0.06, "output": 0.12},
        "gpt-4-32k-0613": {"input": 0.06, "output": 0.12},
        "gpt-4-32k-0314": {"input": 0.06, "output": 0.12},
        # ===========================================
        # GPT-3.5 Turbo ê³„ì—´
        # ===========================================
        "gpt-3.5-turbo": {"input": 0.0005, "output": 0.0015},
        "gpt-3.5-turbo-0125": {"input": 0.0005, "output": 0.0015},
        "gpt-3.5-turbo-1106": {"input": 0.001, "output": 0.002},
        "gpt-3.5-turbo-0613": {"input": 0.0015, "output": 0.002},
        "gpt-3.5-turbo-0301": {"input": 0.0015, "output": 0.002},
        "gpt-3.5-turbo-16k": {"input": 0.003, "output": 0.004},
        "gpt-3.5-turbo-16k-0613": {"input": 0.003, "output": 0.004},
        "gpt-3.5-turbo-instruct": {"input": 0.0015, "output": 0.002},
        # ===========================================
        # ChatGPT ê³„ì—´
        # ===========================================
        "chatgpt-4o-latest": {"input": 0.005, "output": 0.015},  # Same as GPT-4o
        # ===========================================
        # Base Models (Completion/Legacy)
        # ===========================================
        "davinci-002": {"input": 0.002, "output": 0.002},
        "babbage-002": {"input": 0.0004, "output": 0.0004},
        "text-davinci-003": {"input": 0.02, "output": 0.02},
        "text-davinci-002": {"input": 0.02, "output": 0.02},
        # ===========================================
        # Fine-tuning Models
        # ===========================================
        "gpt-4o-fine-tuned": {
            "input": 0.005,
            "output": 0.015,
        },  # Training: $25/1M tokens
        "gpt-4o-mini-fine-tuned": {
            "input": 0.0003,
            "output": 0.0012,
        },  # Training: $3/1M tokens
        "gpt-3.5-turbo-fine-tuned": {
            "input": 0.003,
            "output": 0.006,
        },  # Training: $8/1M tokens
        "davinci-002-fine-tuned": {
            "input": 0.006,
            "output": 0.006,
        },  # Training: $6/1M tokens
        "babbage-002-fine-tuned": {
            "input": 0.0016,
            "output": 0.0016,
        },  # Training: $2.4/1M tokens
        # ===========================================
        # Experimental/Preview Models
        # ===========================================
        "gpt-4-with-browsing": {"input": 0.03, "output": 0.06},  # Deprecated
        "gpt-4-code-interpreter": {"input": 0.03, "output": 0.06},  # Deprecated
        "gpt-4-plugins": {"input": 0.03, "output": 0.06},  # Deprecated
    }

    # ì •í™•í•œ ëª¨ë¸ëª… ë§¤ì¹­
    if model_name in known_prices:
        return known_prices[model_name]

    # íŒ¨í„´ ê¸°ë°˜ ì¶”ì •
    model_lower = model_name.lower()

    # GPT-5 ê³„ì—´
    if "gpt-5" in model_lower:
        if "mini" in model_lower:
            return {"input": 0.0003, "output": 0.001}
        elif "turbo" in model_lower:
            return {"input": 0.005, "output": 0.02}
        else:
            return {"input": 0.01, "output": 0.04}

    # O3 ê³„ì—´
    elif "o3" in model_lower:
        if "mini" in model_lower:
            return {"input": 0.004, "output": 0.016}
        else:
            return {"input": 0.02, "output": 0.08}

    # O1 ê³„ì—´
    elif "o1" in model_lower:
        if "mini" in model_lower:
            return {"input": 0.003, "output": 0.012}
        else:
            return {"input": 0.015, "output": 0.06}

    # GPT-4o ê³„ì—´
    elif "gpt-4o" in model_lower:
        if "mini" in model_lower:
            return {"input": 0.00015, "output": 0.0006}  # $0.15/$0.60 per 1M
        else:
            return {"input": 0.005, "output": 0.015}  # $5.00/$15.00 per 1M

    # GPT-4 ê³„ì—´
    elif "gpt-4" in model_lower:
        if "32k" in model_lower:
            return {"input": 0.06, "output": 0.12}
        elif "turbo" in model_lower or "preview" in model_lower:
            return {"input": 0.01, "output": 0.03}
        else:
            return {"input": 0.03, "output": 0.06}

    # GPT-3.5 ê³„ì—´
    elif "gpt-3.5" in model_lower:
        if "16k" in model_lower:
            return {"input": 0.003, "output": 0.004}
        elif "instruct" in model_lower:
            return {"input": 0.0015, "output": 0.002}
        else:
            return {"input": 0.0005, "output": 0.0015}

    # ChatGPT ê³„ì—´
    elif "chatgpt" in model_lower:
        return {"input": 0.005, "output": 0.015}

    # Base models
    elif "davinci" in model_lower:
        return {"input": 0.002, "output": 0.002}
    elif "babbage" in model_lower:
        return {"input": 0.0004, "output": 0.0004}

    # ê¸°ë³¸ê°’ (GPT-3.5-turbo ìˆ˜ì¤€)
    else:
        return {"input": 0.001, "output": 0.002}


def upsert_model_pricing():
    """OpenAI ëª¨ë¸ë“¤ì˜ ê°€ê²© ì •ë³´ë¥¼ BigQueryì— UPSERT (ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸ + ìƒˆ ë°ì´í„° ì‚½ì…)"""

    # 1. OpenAIì—ì„œ ì±„íŒ… ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    chat_models = get_openai_chat_models()

    if not chat_models:
        print("âŒ ì±„íŒ… ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    # 2. ê¸°ì¡´ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
    print("ğŸ“‹ ê¸°ì¡´ ëª¨ë¸ ê°€ê²© ì •ë³´ ì¡°íšŒ ì¤‘...")
    existing_models_query = f"""
    SELECT model_name, input_per_1k, output_per_1k 
    FROM `{PROJECT_ID}.{DATASET_ID}.model_pricing` 
    WHERE effective_to IS NULL
    """

    try:
        existing_models_result = bq_client.query(existing_models_query)
        existing_models = {
            row.model_name: {
                "input": float(row.input_per_1k),
                "output": float(row.output_per_1k),
            }
            for row in existing_models_result
        }
        print(f"âœ… ê¸°ì¡´ ëª¨ë¸ {len(existing_models)}ê°œ í™•ì¸")
    except Exception as e:
        print(f"âš ï¸ ê¸°ì¡´ ëª¨ë¸ ì¡°íšŒ ì‹¤íŒ¨ (í…Œì´ë¸”ì´ ë¹„ì–´ìˆì„ ìˆ˜ ìˆìŒ): {e}")
        existing_models = {}

    # 3. ê° ëª¨ë¸ì— ëŒ€í•œ ê°€ê²© ì •ë³´ ìƒì„± ë° ë¹„êµ
    new_models = []
    updated_models = []
    unchanged_models = []
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    print(f"ğŸ’° {len(chat_models)}ê°œ ëª¨ë¸ì˜ ê°€ê²© ì •ë³´ ë¶„ì„ ì¤‘...")

    for model_name in chat_models:
        pricing = get_model_pricing_data(model_name)
        new_pricing = {"input": pricing["input"], "output": pricing["output"]}

        if model_name in existing_models:
            existing_pricing = existing_models[model_name]
            if (
                existing_pricing["input"] != new_pricing["input"]
                or existing_pricing["output"] != new_pricing["output"]
            ):
                updated_models.append(
                    {
                        "model_name": model_name,
                        "old_input": existing_pricing["input"],
                        "old_output": existing_pricing["output"],
                        "new_input": new_pricing["input"],
                        "new_output": new_pricing["output"],
                    }
                )
            else:
                unchanged_models.append(model_name)
        else:
            new_models.append(
                {
                    "model_name": model_name,
                    "input_per_1k": new_pricing["input"],
                    "output_per_1k": new_pricing["output"],
                    "effective_from": current_time,
                    "effective_to": None,
                }
            )

    # 4. ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    print("\nğŸ“Š ë¶„ì„ ê²°ê³¼:")
    print(f"  ğŸ†• ìƒˆë¡œìš´ ëª¨ë¸: {len(new_models)}ê°œ")
    print(f"  ğŸ”„ ì—…ë°ì´íŠ¸ í•„ìš”: {len(updated_models)}ê°œ")
    print(f"  âœ… ë³€ê²½ì‚¬í•­ ì—†ìŒ: {len(unchanged_models)}ê°œ")

    # 5. ê¸°ì¡´ ëª¨ë¸ ì—…ë°ì´íŠ¸ (effective_to ì„¤ì •)
    if updated_models:
        print(f"\nğŸ”„ {len(updated_models)}ê°œ ëª¨ë¸ ê°€ê²© ì—…ë°ì´íŠ¸ ì¤‘...")
        for model_data in updated_models:
            model_name = model_data["model_name"]

            # ê¸°ì¡´ ë ˆì½”ë“œì— effective_to ì„¤ì •
            update_query = f"""
            UPDATE `{PROJECT_ID}.{DATASET_ID}.model_pricing` 
            SET effective_to = '{current_time}'
            WHERE model_name = '{model_name}' AND effective_to IS NULL
            """

            try:
                bq_client.query(update_query)
                print(f"  âœ… {model_name} ê¸°ì¡´ ë ˆì½”ë“œ ë§Œë£Œ ì²˜ë¦¬")
            except Exception as e:
                print(f"  âŒ {model_name} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                return False

            # ìƒˆë¡œìš´ ê°€ê²©ìœ¼ë¡œ ë ˆì½”ë“œ ì‚½ì…
            new_record = {
                "model_name": model_name,
                "input_per_1k": model_data["new_input"],
                "output_per_1k": model_data["new_output"],
                "effective_from": current_time,
                "effective_to": None,
            }
            new_models.append(new_record)

    # 6. ìƒˆë¡œìš´ ëª¨ë¸ë“¤ ì‚½ì…
    if new_models:
        print(f"\nâ• {len(new_models)}ê°œ ëª¨ë¸ ë°ì´í„° ì‚½ì… ì¤‘...")
        table_ref = bq_client.dataset(DATASET_ID).table("model_pricing")

        try:
            errors = bq_client.insert_rows_json(table_ref, new_models)
            if errors:
                print(f"âŒ ë°ì´í„° ì‚½ì… ì˜¤ë¥˜: {errors}")
                return False
            else:
                print(f"âœ… ëª¨ë¸ ë°ì´í„° {len(new_models)}ê°œ ì‚½ì… ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì‚½ì… ì‹¤íŒ¨: {e}")
            return False

    # 7. ê²°ê³¼ ìƒì„¸ ì¶œë ¥
    if updated_models:
        print("\nğŸ”„ ì—…ë°ì´íŠ¸ëœ ëª¨ë¸ë“¤:")
        for model_data in updated_models[:10]:  # ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ
            print(
                f"  â€¢ {model_data['model_name']:<35} "
                f"${model_data['old_input']:.6f}â†’${model_data['new_input']:.6f} / "
                f"${model_data['old_output']:.6f}â†’${model_data['new_output']:.6f}"
            )
        if len(updated_models) > 10:
            print(f"  ... ì™¸ {len(updated_models) - 10}ê°œ ëª¨ë¸")

    if new_models:
        print("\nğŸ†• ìƒˆë¡œ ì¶”ê°€ëœ ëª¨ë¸ë“¤:")
        for data in new_models[:10]:  # ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ
            print(
                f"  â€¢ {data['model_name']:<35} ì…ë ¥: ${data['input_per_1k']:<8} ì¶œë ¥: ${data['output_per_1k']}"
            )
        if len(new_models) > 10:
            print(f"  ... ì™¸ {len(new_models) - 10}ê°œ ëª¨ë¸")

    # GPT-5, O3 ë“± ìµœì‹  ëª¨ë¸ë“¤ í•˜ì´ë¼ì´íŠ¸
    latest_new_models = [
        m
        for m in new_models
        if any(keyword in m["model_name"].lower() for keyword in ["gpt-5", "o3", "o1"])
    ]
    if latest_new_models:
        print("\nğŸ”¥ ìƒˆë¡œ ì¶”ê°€ëœ ìµœì‹  ëª¨ë¸ë“¤:")
        for data in latest_new_models:
            print(
                f"  â€¢ {data['model_name']:<35} ì…ë ¥: ${data['input_per_1k']:<8} ì¶œë ¥: ${data['output_per_1k']}"
            )

    print(f"\nâœ… ì´ {len(chat_models)}ê°œ ëª¨ë¸ ì²˜ë¦¬ ì™„ë£Œ!")
    return True


# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ê¸°ì¡´ í•¨ìˆ˜ëª…ë„ ìœ ì§€
def insert_model_pricing():
    """ê¸°ì¡´ í•¨ìˆ˜ëª… í˜¸í™˜ì„± ìœ ì§€"""
    return upsert_model_pricing()


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ’° ëª¨ë¸ ê°€ê²© ì •ë³´ ì‚½ì…ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n")

    try:
        # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
        dataset_id = f"{PROJECT_ID}.{DATASET_ID}"
        required_tables = ["model_pricing", "run_log"]

        for table_name in required_tables:
            table_id = f"{dataset_id}.{table_name}"
            try:
                bq_client.get_table(table_id)
                print(f"âœ… í…Œì´ë¸” í™•ì¸: {table_name}")
            except Exception:
                print(f"âŒ í…Œì´ë¸” ì—†ìŒ: {table_name}")
                print(f"ğŸ’¡ BigQuery ì½˜ì†”ì—ì„œ {table_name} í…Œì´ë¸”ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
                return

        print("\nğŸ“ ë°ì´í„° ì‚½ì… ì¤‘...")

        # ëª¨ë¸ ê°€ê²© ì •ë³´ ì‚½ì…
        if insert_model_pricing():
            print("âœ… ëª¨ë¸ ê°€ê²© ì •ë³´ ì‚½ì… ì„±ê³µ")
            print("\nğŸ‰ ëª¨ë¸ ê°€ê²© ì •ë³´ ì—…ë°ì´íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            print("ğŸ’¡ ì´ì œ Streamlit ì•±ì—ì„œ ìµœì‹  ëª¨ë¸ë“¤ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
            print("ğŸš€ ì‹¤í–‰: streamlit run test_ai.py")
        else:
            print("âŒ ëª¨ë¸ ê°€ê²© ì •ë³´ ì‚½ì… ì‹¤íŒ¨")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return


if __name__ == "__main__":
    main()
